
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Orthogonal Adaptation for Modular Customization of Diffusion Models</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title" style = "font-size: 30px;">Orthogonal Adaptation for Modular Customization of Diffusion Models</h1>


          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ryanpo.com">Ryan Po</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.guandaoyang.com/">Guandao Yang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://kfiraberman.github.io/">Kfir Aberman</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://stanford.edu/~gordonwz/">Gordon Wetzstein</a><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Stanford University,</span>
            <span class="author-block"><sup>2</sup>Snap Research</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="static/pdf/orth.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2312.02432"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="hero teaser" style="overflow: hidden;">
  <div class="container is-max-desktop" style="overflow: hidden;">
    <div class="hero-body" style="overflow: hidden;">
      <div class="video-wrapper">
      <center>
      <video id="teaser" autoplay muted loop playsinline width="100%" controls>
        <source src="./static/videos/teaser.mp4" type="video/mp4">
      </video>
      </center>
      </div>
    </div>
  </div>
</section>





<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">


    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div>
          <h2 class="title is-3" style = "font-size: 25px;">Abstract</h2>
          <div class="content has-text-justified">
            
            <p>
              Customization techniques for text-to-image models have paved the way for a wide range of previously unattainable applications, enabling the generation of specific concepts across diverse contexts and styles. While existing methods facilitate high-fidelity customization for individual concepts or a limited, pre-defined set of them, they fall short of achieving scalability, where a single model can seamlessly render countless concepts. In this paper, we address a new problem called Modular Customization, with the goal of efficiently merging customized models that were fine-tuned independently for individual concepts. This allows the merged model to jointly synthesize concepts in one image without compromising fidelity or incurring any additional computational costs.
            </p>
            <p>
              To address this problem, we introduce Orthogonal Adaptation, a method designed to encourage the customized models, which do not have access to each other during fine-tuning, to have orthogonal residual weights. This ensures that during inference time, the customized models can be summed with minimal interference. 
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/mod-cus.png" alt="Italian Trulli" width = "120%">
      
          </div>


          <!-- <div style="width: 30%; float:left">
            <img src="./static/images/mod-cus.png" alt="Italian Trulli" width = "100%">
          </div>
          <div style="width: 2%; float: left">
            &nbsp
          </div>
          <div style="width: 68%; float:left">
          <div class="content has-text-justified">
            <p>
              Customization techniques for text-to-image models have paved the way for a wide range of previously unattainable applications, enabling the generation of specific concepts across diverse contexts and styles. While existing methods facilitate high-fidelity customization for individual concepts or a limited, pre-defined set of them, they fall short of achieving scalability, where a single model can seamlessly render countless concepts. In this paper, we address a new problem called Modular Customization, with the goal of efficiently merging customized models that were fine-tuned independently for individual concepts. This allows the merged model to jointly synthesize concepts in one image without compromising fidelity or incurring any additional computational costs.
            </p>
            <p>
              To address this problem, we introduce Orthogonal Adaptation, a method designed to encourage the customized models, which do not have access to each other during fine-tuning, to have orthogonal residual weights. This ensures that during inference time, the customized models can be summed with minimal interference. 
            </p>
          </div>
        </div> -->
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
    </section>
    
  <div></div>


</section>


<section class="section">

  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div>
        <h2 class="title is-3" style = "font-size: 25px;">Multi-concept Results</h2>
        <div class="content has-text-justified">
          <div class="content has-text-centered">
            <img src="./static/images/gallery-1.png" alt="Italian Trulli" width = "120%">
      
          </div>
          <p>
            Our method enables efficient merging of individually fine-tuned concepts for modular, efficient multi-concept customization of text-to-image diffusion models. Each concept shown above was fine-tuned individually using orthogonal adaptation. Fine-tuned weight residuals are then merged via summation, enabling multi-concept generation.          </p>
        </div>
      </div>
    </div>
    <!--/ Method. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">


    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div>
          <h2 class="title is-3" style = "font-size: 25px;">Problem: LoRA Crosstalk</h2>
          <div class="content has-text-centered">
            <img src="./static/images/crosstalk_supp.png" alt="Italian Trulli" width = "120%">
      
          </div>
          <div class="content has-text-justified">
            
            <p>LoRAs fine-tuned under conventional methods interfere with one another when combined naively, this effect is most noticeable when LoRA weights are similar. We refer to this effect as "crosstalk". 
              
              The effects of crosstalk lead to loss of identity for customized concepts as observed on the results to the right. 
              
              The goal of our method is to modify the fine-tuning regime such that resulting LoRAs have minimal crosstalk. 
              
              A key observation from our experiments is that <b><em> crosstalk is minimized when LoRA weights are orthogonal to each other</em></b>. 

              Measuring crosstalk through the norm of the product between two LoRA weights, our method results in lower crosstalk between independently trained LoRAs. 
              
              Combined via the same method, our training regime leads to less crosstalk and therefore better identity preservation after merging.            
             </p>
          </div>
          
          <!-- <div style="width: 52%; float:left">
          <div class="content has-text-justified">
            <p>
              LoRAs fine-tuned under conventional methods interfere with one another when combined naively, this effect is most noticeable when LoRA weights are similar. We refer to this effect as "crosstalk". 
              
              The effects of crosstalk lead to loss of identity for customized concepts as observed on the results to the right. 
              
              The goal of our method is to modify the fine-tuning regime such that resulting LoRAs have minimal crosstalk. 
              
              A key observation from our experiments is that <b><em> crosstalk is minimized when LoRA weights are orthogonal to each other</em></b>. 

              Measuring crosstalk through the norm of the product between two LoRA weights, our method results in lower crosstalk between independently trained LoRAs. 
              
              Combined via the same method, our training regime leads to less crosstalk and therefore better identity preservation after merging.            </p>
  
          </div>
          
          
          
        </div>
        <div style="width: 2%; float: left">
          &nbsp
        </div>
        <div style="width: 46%; float:left">
          <img src="./static/images/crosstalk_supp-1.png" alt="Italian Trulli" width = "100%">
        </div>
        </div> -->
      </div>
      <!--/ Abstract. -->
    </div>
    </section>
    
  <div></div>


</section>


<section class="section">

  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div>
        <h2 class="title is-3" style = "font-size: 25px;">Method</h2>
        <div class="content has-text-justified">
          <div class="content has-text-centered">
            <img src="./static/images/method-1.png" alt="Italian Trulli" width = "120%">
      
          </div>
          <p>
            Overview of our method. (a) LoRA enables training of both low-rank decomposed matrices. (b) Orthogonal adaption constrains training only to A, leaving B fixed. (c) For two separate concepts, i and j, an orthogonality constraint is imposed between B_i and B_j. (d) When concepts i and j are trained independently, approximate orthogonality between B_i and B_j can be achieved by sampling random columns from a shared orthogonal matrix. (e) Without the orthogonality constraint, correlated concepts suffer from "crosstalk" when merged; with the orthogonality constraint, orthogonal concepts preserve their identities after merging.
          </p>
        </div>
      </div>
    </div>
    <!--/ Method. -->
  </div>
</section>



<section class="section">

  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div>
        <h2 class="title is-3" style = "font-size: 25px;">Results</h2>
        <div class="content has-text-justified">
          <div class="content has-text-centered">
            <img src="./static/images/multi-concept-1.png" alt="Italian Trulli" width = "120%">
      
          </div>
          <p>
            Orthogonal adaptation out-performs state-of-the-art baselines for multi-concept generations. While other methods suffer from identity loss due to crosstalk between individually trained LoRAs, models fine-tuned using orthogonal adaptation results in lower crosstalk, leading to better preservation of individual subject identities in the merged model.
          </p>
         </div>

         <div class="content has-text-justified">
          <div class="content has-text-centered">
            <img src="./static/images/identity.jpg" alt="Italian Trulli" width = "80%">
      
          </div>
          <p>
            Our method outperforms competing baselines in identity preservation, while keeping merging costs low. Methods with competing levels of quality (e.g. Mix-of-Show w/ Gradient Fusion) requires an additional optimization-based merging procedure. 
            A key contribution of our method is that LoRAs trained using orthogonal adaptation can be mergeed via naive summation while experiencing minimal subject identity loss.
          </p>
         </div>
        </div>
      </div>
    </div>
    <!--/ Method. -->
  </div>
  
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{po2023orthogonal,
      title={Orthogonal Adaptation for Modular Customization of Diffusion Models}, 
      author={Ryan Po and Guandao Yang and Kfir Aberman and Gordon Wetzstein},
      year={2023},
      eprint={2312.02432},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
      }</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>



</body>
</html>
